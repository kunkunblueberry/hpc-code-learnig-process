🔥 CUDA Reduce: 从入门到极致优化的归约实现（火热连载，后续应该还会出前缀和的优化，更深一步了解cuda优化）



这是一个 CUDA 归约（Reduction）算法 的渐进式优化仓库，从最基础的实现逐步迭代到工业级高效版本。
每个分支对应一个优化阶段，清晰展示 CUDA 并行编程的核心优化思路（内存访问、线程协作、编译优化等），适合 CUDA 初学者入门并行计算，也适合进阶开发者参考性能调优技巧。



📚 什么是归约（Reduction）？
归约是将一个 多维数组 通过二元运算（如求和、求均值、求最大值）压缩为 单个 / 多个结果 的过程，是深度学习、科学计算中的核心操作（例如损失函数计算、特征统计）。
举个例子：
输入数组 [1,2,3,4,5,6,7,8] → 归约求和 → 输出 36



🔄 优化迭代路线（按分支查看）
每个分支对应一个优化阶段，代码从简单到复杂，性能逐步提升。建议按顺序学习，理解每一步优化的核心价值。
分支名称	      核心优化点	    性能提升点	    适用场景
v1-basic	      基础单块归约，无优化	实现最简化逻辑，理解归约流程	CUDA 入门学习
v2-shared-mem	  引入共享内存（__shared__）	减少全局内存访问，降低延迟	中等规模数据归约
v3-warp-opt	    利用 Warp 隐式同步，移除冗余同步	减少 __syncthreads() 开销	线程块大小 ≥ 32 的场景
v4-volatile	    共享内存加 volatile，防止编译优化	避免 warp 内读取旧值，保证结果正确	无显式同步的 warp 操作
v5-loop-unroll	#pragma unroll 循环展开	消除循环控制开销，提升指令并行度	固定迭代次数的归约步骤
v6-template	    模板函数固化线程块大小	编译期优化，消除运行时分支	多线程块大小适配
v7-final	       融合所有优化 + 多精度支持	工业级性能，支持 float/half	生产环境部署
🚀 快速开始
1. 环境要求
NVIDIA GPU（计算能力 ≥ 7.0，如 RTX 20/30/40 系列、Tesla T4/V100）
CUDA Toolkit ≥ 11.0
CMake ≥ 3.18（可选，用于多平台编译）
GCC/Clang 支持 C++11 及以上
2. 编译与运行
方式 1：直接用 nvcc 编译
# 切换到目标分支（以 v1-basic 为例）
git checkout v1-basic

# 编译（指定 GPU 计算能力，如 sm_75 对应 RTX 20 系列）
nvcc reduce.cu -arch=sm_75 -o reduce              //一定要指定架构哦，不然无法编译成功

# 运行
./reduce
